{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f88c0e99-93ab-438f-8bee-4313d2a42eb6",
   "metadata": {},
   "source": [
    "# SenseSmart\n",
    "\n",
    "*Jerry Zhao, Xuying Yang, Yujuan Zhou, Clement Mo, Haozheng Liu*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096b3a06-aaaa-4b05-8e99-6a8406c0e73f",
   "metadata": {},
   "source": [
    "## Project Name: Social Media Sentiment Analysis Dataset\n",
    "**Dataset**: [Social Media Sentiment Analysis Dataset](https://www.kaggle.com/datasets/kashishparmar02/social-media-sentiments-analysis-dataset/code)\n",
    "\n",
    "This project aims to analyze user-generated content across various social media platforms to uncover sentiment trends and user behavior. The dataset offers a rich source of data, including text-based content, user sentiments, timestamps, hashtags, user engagement metrics (likes and retweets), and geographical information. By exploring this data, we can identify how emotions fluctuate over time, platform, and geography. We will also investigate the correlation between popular content and user engagement metrics. \n",
    "\n",
    "**Problem Statement:**\n",
    "The primary goal is to perform sentiment analysis, investigate temporal and geographical trends in user-generated content, and analyze platform-specific user behavior. The project will focus on identifying popular topics through hashtags, exploring engagement levels, and understanding regional differences in sentiment trends. \n",
    "\n",
    "**Tasks:**\n",
    "- **Dataset Exploration:**\n",
    "  - Gain familiarity with the dataset by understanding its structure and key features such as sentiment, timestamps, and user engagement (likes and retweets).\n",
    "- **Sentiment Analysis:**\n",
    "  - Conduct sentiment analysis to classify the user-generated content into different categories such as surprise, excitement, admiration, etc.\n",
    "  - Visualize the distribution of sentiments and examine the emotional landscape of social media platforms.\n",
    "- **Temporal Analysis:**\n",
    "  - Explore temporal patterns in user sentiment over time using the \"Timestamp\" column.\n",
    "  - Identify recurring themes, seasonal variations, or any significant trends in the data.\n",
    "- **User Engagement Insights:**\n",
    "  - Analyze user engagement by studying the likes and retweets associated with posts.\n",
    "  - Investigate how sentiment correlates with higher levels of user engagement.\n",
    "- **Platform-Specific Analysis:**\n",
    "  -  Compare sentiment trends across various platforms using the \"Platform\" column.\n",
    "  -  Identify how emotions differ depending on the platform.\n",
    "- **Hashtag and Topic Trends:**\n",
    "  - Explore trending topics by analyzing the hashtags.\n",
    "  - Investigate the relationship between hashtags and user engagement or sentiment.\n",
    "- **Geographical Trends:**\n",
    "  - Examine regional sentiment variations using the \"Country\" column.\n",
    "  - Understand how social media content and sentiment differ across various regions.\n",
    "- **Cross-Feature Analysis:**\n",
    "  - Combine features (e.g., sentiment and hashtags, sentiment and platform) to uncover deeper insights about user behavior and content trends.\n",
    "- **Predictive Modeling (Optional):**\n",
    "  - Explore the possibility of building predictive models to predict user engagement (likes/retweets) based on sentiment, hashtags, and platform.\n",
    "  - Evaluate the performance of the model and explore its potential for predicting popular content. \n",
    "\n",
    "Students are encouraged to draw connections between data-driven insights and potential policy implications.\n",
    "\n",
    "Students are encouraged to draw connections between data-driven insights and potential policy implications. The project should foster a deeper understanding of the dynamics of air quality in India and its impact on public health and the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a664fc4c-96a2-4e15-aa37-022aa0247613",
   "metadata": {},
   "source": [
    "## Dataset acquisition\n",
    "**Dataset**: [Social Media Sentiment Analysis Dataset](https://www.kaggle.com/datasets/kashishparmar02/social-media-sentiments-analysis-dataset/code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b34f726-8afe-48fc-83d1-d9192a2b52fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install needed packages\n",
    "%pip -q install kagglehub pandas matplotlib scikit-learn nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "565685d9-1447-4d58-aaf5-82661fce1a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KaggleHub cache: C:\\Users\\yujua\\.cache\\kagglehub\\datasets\\kashishparmar02\\social-media-sentiments-analysis-dataset\\versions\\3\n",
      "Path to dataset files: C:\\Users\\yujua\\Desktop\\F25\\DataScience_BootCamp\\SenseSmart\\data , the dataset file name is: ['sentimentdataset.csv']\n"
     ]
    }
   ],
   "source": [
    "# Download dataset\n",
    "from pathlib import Path\n",
    "import kagglehub, zipfile, shutil\n",
    "\n",
    "# # Download latest version\n",
    "# path = kagglehub.dataset_download(\"kashishparmar02/social-media-sentiments-analysis-dataset\")\n",
    "cache = Path(kagglehub.dataset_download(\"kashishparmar02/social-media-sentiments-analysis-dataset\"))\n",
    "print(\"KaggleHub cache:\", cache)\n",
    "\n",
    "# Prepare and clear ./data folder\n",
    "data_dir = Path(\"data\")\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "for p in data_dir.iterdir():\n",
    "    if p.is_file():\n",
    "        p.unlink() # remove file\n",
    "    else:\n",
    "        shutil.rmtree(p)\n",
    "\n",
    "# Collect .csv files\n",
    "csv_found = []\n",
    "for f in cache.rglob(\"*.csv\"):\n",
    "    dst = data_dir / f.name\n",
    "    if not dst.exists(): # Avoid duplicates\n",
    "        shutil.copy2(f, dst)\n",
    "        csv_found.append(dst.name)\n",
    "\n",
    "# If none found, scan all zips and extract ONLY .csv files into ./data\n",
    "if not csv_found:\n",
    "    for z in cache.rglob(\"*.zip\"):\n",
    "        try:\n",
    "            with zipfile.ZipFile(z) as zf:\n",
    "                for member in zf.infolist():\n",
    "                    # Filter by extension .csv\n",
    "                    name = Path(member.filename).name\n",
    "                    if name.lower().endswith(\".csv\"):\n",
    "                        with zf.open(member) as src, open(data_dir / name, \"wb\") as dst:\n",
    "                            shutil.copyfileobj(src, dst)\n",
    "                        csv_found.append(name)\n",
    "        except Exception as e:\n",
    "            print(\"Skip bad zip:\", z, \"->\", e)\n",
    "\n",
    "# 5) ç»“æžœæ£€æŸ¥ä¸Žå›žæ˜¾ / Verify result and show summary\n",
    "if not csv_found:\n",
    "    raise FileNotFoundError(\"No .csv found.\")\n",
    "print(\"Path to dataset files:\", data_dir.resolve(), \", the dataset file name is:\", csv_found)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a8ee6af-39c3-4303-989d-40b56cca4c66",
   "metadata": {},
   "source": [
    "## Load Data & Column Standardization\n",
    "Text â€” the post text\n",
    "Sentiment â€” emotion label (e.g., Positive, Negative, Neutral, ...)\n",
    "Timestamp â€” time the post was made\n",
    "Platform â€” social platform name\n",
    "Likes â€” number of likes\n",
    "Retweets â€” number of retweets\n",
    "Country â€” country string\n",
    "Hashtags â€” raw hashtag text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9f796d0-96f3-4b57-b048-13065e3119a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected file: sentimentdataset.csv\n",
      "Raw shape: (732, 15)\n",
      "Raw columns: ['Unnamed: 0.1', 'Unnamed: 0', 'Text', 'Sentiment', 'Timestamp', 'User', 'Platform', 'Hashtags', 'Retweets', 'Likes', 'Country', 'Year', 'Month', 'Day', 'Hour']\n",
      "Dropped Unnamed columns: ['Unnamed: 0.1', 'Unnamed: 0']\n",
      "\n",
      "Previewï¼š\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>User</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enjoying a beautiful day at the park!        ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2023-01-15 12:30:00</td>\n",
       "      <td>User123</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>#Nature #Park</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Traffic was terrible this morning.           ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2023-01-15 08:45:00</td>\n",
       "      <td>CommuterX</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>#Traffic #Morning</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just finished an amazing workout! ðŸ’ª          ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2023-01-15 15:45:00</td>\n",
       "      <td>FitnessFan</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>#Fitness #Workout</td>\n",
       "      <td>20.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excited about the upcoming weekend getaway!  ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2023-01-15 18:20:00</td>\n",
       "      <td>AdventureX</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>#Travel #Adventure</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>UK</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trying out a new recipe for dinner tonight.  ...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2023-01-15 19:55:00</td>\n",
       "      <td>ChefCook</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>#Cooking #Food</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text    Sentiment  \\\n",
       "0   Enjoying a beautiful day at the park!        ...   Positive     \n",
       "1   Traffic was terrible this morning.           ...   Negative     \n",
       "2   Just finished an amazing workout! ðŸ’ª          ...   Positive     \n",
       "3   Excited about the upcoming weekend getaway!  ...   Positive     \n",
       "4   Trying out a new recipe for dinner tonight.  ...   Neutral      \n",
       "\n",
       "             Timestamp            User     Platform  \\\n",
       "0  2023-01-15 12:30:00   User123          Twitter     \n",
       "1  2023-01-15 08:45:00   CommuterX        Twitter     \n",
       "2  2023-01-15 15:45:00   FitnessFan      Instagram    \n",
       "3  2023-01-15 18:20:00   AdventureX       Facebook    \n",
       "4  2023-01-15 19:55:00   ChefCook        Instagram    \n",
       "\n",
       "                                     Hashtags  Retweets  Likes       Country  \\\n",
       "0   #Nature #Park                                  15.0   30.0     USA         \n",
       "1   #Traffic #Morning                               5.0   10.0     Canada      \n",
       "2   #Fitness #Workout                              20.0   40.0   USA           \n",
       "3   #Travel #Adventure                              8.0   15.0     UK          \n",
       "4   #Cooking #Food                                 12.0   25.0    Australia    \n",
       "\n",
       "   Year  Month  Day  Hour  \n",
       "0  2023      1   15    12  \n",
       "1  2023      1   15     8  \n",
       "2  2023      1   15    15  \n",
       "3  2023      1   15    18  \n",
       "4  2023      1   15    19  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape: (732, 13)\n",
      "Final columns: ['Text', 'Sentiment', 'Timestamp', 'User', 'Platform', 'Hashtags', 'Retweets', 'Likes', 'Country', 'Year', 'Month', 'Day', 'Hour']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd, numpy as np, re, json, warnings\n",
    "from IPython.display import display\n",
    "\n",
    "# Data directory ./data\n",
    "DATA_DIR = Path(\"data\")\n",
    "\n",
    "# Pick the dataset file in ./data\n",
    "csv_files = sorted(DATA_DIR.glob(\"*.csv\"))\n",
    "if not csv_files:\n",
    "    raise FileNotFoundError(\"No data file found in ./data.\\n\")\n",
    "DATA_FILE = csv_files[0]\n",
    "print(\"Selected file:\", DATA_FILE.name)\n",
    "\n",
    "# Read the CSV\n",
    "df = pd.read_csv(DATA_FILE, low_memory=False)\n",
    "print(\"Raw shape:\", df.shape)\n",
    "print(\"Raw columns:\", list(df.columns))\n",
    "\n",
    "# Normalize original column names to lowercase + strip for matching\n",
    "# df = df.rename(columns={c: str(c).lower().strip() for c in df.columns})\n",
    "\n",
    "# Drop index-duplicates: Unnamed\n",
    "unnamed_cols = [c for c in df.columns if re.match(r\"^Unnamed\", str(c), flags=re.IGNORECASE)]\n",
    "if unnamed_cols:\n",
    "    df = df.drop(columns=unnamed_cols)\n",
    "    print(\"Dropped Unnamed columns:\", unnamed_cols)\n",
    "\n",
    "# Preview\n",
    "desired_order = [\"Text\", \"Sentiment\", \"Timestamp\", \"User\", \n",
    "                 \"Platform\", \"Hashtags\", \"Retweets\", \"Likes\", \n",
    "                 \"Country\", \"Year\", \"Month\", \"Day\", \"Hour\"\n",
    "]\n",
    "\n",
    "if all(col in df.columns for col in desired_order):\n",
    "    view = df[desired_order]\n",
    "else:\n",
    "    present = [c for c in desired_order if c in df.columns]\n",
    "    others  = [c for c in df.columns if c not in present]\n",
    "    view = df[present + others]\n",
    "print(\"\\nPreviewï¼š\")\n",
    "display(view.head())\n",
    "\n",
    "print(\"Final shape:\", view.shape)\n",
    "print(\"Final columns:\", list(view.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ad55ca-0dbe-4fb2-a17a-a2e7093b4fad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9109b327-5c6a-4612-a6f6-349c882ff81d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
